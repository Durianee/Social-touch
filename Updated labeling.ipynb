{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "workflow:\n",
    "\n",
    "Load the ResNet model from models.py.\n",
    "\n",
    "Extract frames from videos at a specified rate.\n",
    "\n",
    "Use the model to predict labels for these frames.\n",
    "\n",
    "Map the predictions to the labels provided in your text files (category_momentsv2.txt and category_multi_momentsv2.txt).\n",
    "\n",
    "Compile the results into a CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Download and Run the model.py first (from github)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. import model class (resnet50), load model and process video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: Couldn't read video stream from file \"/Users/wangjiji/Desktop/Social touch deep learning project/STMP4/006.mp4\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping: Could not open /Users/wangjiji/Desktop/Social touch deep learning project/STMP4/006.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: Couldn't read video stream from file \"/Users/wangjiji/Desktop/Social touch deep learning project/STMP4/009.mp4\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping: Could not open /Users/wangjiji/Desktop/Social touch deep learning project/STMP4/009.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: Couldn't read video stream from file \"/Users/wangjiji/Desktop/Social touch deep learning project/STMP4/021.mp4\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping: Could not open /Users/wangjiji/Desktop/Social touch deep learning project/STMP4/021.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: Couldn't read video stream from file \"/Users/wangjiji/Desktop/Social touch deep learning project/STMP4/023.mp4\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping: Could not open /Users/wangjiji/Desktop/Social touch deep learning project/STMP4/023.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: Couldn't read video stream from file \"/Users/wangjiji/Desktop/Social touch deep learning project/STMP4/031.mp4\"\n",
      "OpenCV: Couldn't read video stream from file \"/Users/wangjiji/Desktop/Social touch deep learning project/STMP4/032.mp4\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping: Could not open /Users/wangjiji/Desktop/Social touch deep learning project/STMP4/031.mp4\n",
      "Skipping: Could not open /Users/wangjiji/Desktop/Social touch deep learning project/STMP4/032.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: Couldn't read video stream from file \"/Users/wangjiji/Desktop/Social touch deep learning project/STMP4/034.mp4\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping: Could not open /Users/wangjiji/Desktop/Social touch deep learning project/STMP4/034.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: Couldn't read video stream from file \"/Users/wangjiji/Desktop/Social touch deep learning project/STMP4/036.mp4\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping: Could not open /Users/wangjiji/Desktop/Social touch deep learning project/STMP4/036.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: Couldn't read video stream from file \"/Users/wangjiji/Desktop/Social touch deep learning project/STMP4/040.mp4\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping: Could not open /Users/wangjiji/Desktop/Social touch deep learning project/STMP4/040.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: Couldn't read video stream from file \"/Users/wangjiji/Desktop/Social touch deep learning project/STMP4/046.mp4\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping: Could not open /Users/wangjiji/Desktop/Social touch deep learning project/STMP4/046.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: Couldn't read video stream from file \"/Users/wangjiji/Desktop/Social touch deep learning project/STMP4/053.mp4\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping: Could not open /Users/wangjiji/Desktop/Social touch deep learning project/STMP4/053.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: Couldn't read video stream from file \"/Users/wangjiji/Desktop/Social touch deep learning project/STMP4/058.mp4\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping: Could not open /Users/wangjiji/Desktop/Social touch deep learning project/STMP4/058.mp4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/Users/wangjiji/Desktop/moments_models-2')  # Replace with the path to your models.py\n",
    "from models import resnet50\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Load the model\n",
    "model = resnet50(pretrained=True)  # Ensure this matches your specific function to load resnet50\n",
    "model.eval()\n",
    "\n",
    "# Define the transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),                # Convert numpy array to PIL Image\n",
    "    transforms.Resize((224, 224)),          # Resize the image to 224x224\n",
    "    transforms.ToTensor(),                  # Convert the image to a tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Label mapping from your text file (adjust path as necessary)\n",
    "with open('category_momentsv2.txt', 'r') as f:\n",
    "    labels = {i: label.strip() for i, label in enumerate(f.readlines())}\n",
    "\n",
    "# Directory containing the videos\n",
    "directory = '/Users/wangjiji/Desktop/Social touch deep learning project/STMP4/'\n",
    "\n",
    "# Prepare to collect results\n",
    "results = []\n",
    "\n",
    "# Process each video file from 001 to 071\n",
    "for i in range(1, 72):  # Adjust range for your video numbers\n",
    "    video_number = f\"{i:03}\"\n",
    "    video_path = f\"{directory}{video_number}.mp4\"\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Skipping: Could not open {video_path}\")\n",
    "        continue  # Skip this video file\n",
    "\n",
    "    frame_rate = 16\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    interval = max(int(frame_count / frame_rate), 1)  # Prevents zero division\n",
    "\n",
    "    for frame_id in range(0, frame_count, interval):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_id)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "        \n",
    "        # Apply transformations and predict\n",
    "        tensor = transform(frame)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(tensor.unsqueeze(0))\n",
    "            predicted_label = labels[torch.argmax(outputs).item()]\n",
    "\n",
    "        results.append([video_number, frame_id, predicted_label])\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "# Save results to CSV\n",
    "# Creating the initial DataFrame\n",
    "df = pd.DataFrame(results, columns=['Video', 'Frame', 'Label'])\n",
    "\n",
    "# Pivoting the DataFrame\n",
    "pivot_df = df.pivot(index='Video', columns='Frame', values='Label')\n",
    "\n",
    "# Saving the pivoted DataFrame to CSV\n",
    "pivot_df.to_csv('/Users/wangjiji/Desktop/video_labels.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
